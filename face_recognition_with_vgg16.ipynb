{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 1624149,
          "sourceType": "datasetVersion",
          "datasetId": 959963
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model-1 (Training on Entire Dataset)"
      ],
      "metadata": {
        "id": "eZzs8uEsm_b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "# suppress display of warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:16:55.341721Z",
          "iopub.execute_input": "2024-02-20T07:16:55.342147Z",
          "iopub.status.idle": "2024-02-20T07:17:12.348434Z",
          "shell.execute_reply.started": "2024-02-20T07:16:55.34211Z",
          "shell.execute_reply": "2024-02-20T07:17:12.347555Z"
        },
        "trusted": true,
        "id": "afNH3f-Nm_cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:17:12.349788Z",
          "iopub.execute_input": "2024-02-20T07:17:12.350395Z",
          "iopub.status.idle": "2024-02-20T07:17:12.353889Z",
          "shell.execute_reply.started": "2024-02-20T07:17:12.350365Z",
          "shell.execute_reply": "2024-02-20T07:17:12.353273Z"
        },
        "trusted": true,
        "id": "w8HkpZwFm_cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "e3n-leLUnZXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your train_dir path\n",
        "train_dir = '/content/drive/My Drive/Computer Vision/Face Recognition/Original Images'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:17:12.354615Z",
          "iopub.execute_input": "2024-02-20T07:17:12.35484Z",
          "iopub.status.idle": "2024-02-20T07:17:12.386528Z",
          "shell.execute_reply.started": "2024-02-20T07:17:12.354809Z",
          "shell.execute_reply": "2024-02-20T07:17:12.385521Z"
        },
        "trusted": true,
        "id": "-8Gd-0Yym_cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ImageDataGenerator for data augmentation\n",
        "generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1  # 10% of the data will be used for validation\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:17:12.388462Z",
          "iopub.execute_input": "2024-02-20T07:17:12.38873Z",
          "iopub.status.idle": "2024-02-20T07:17:12.406151Z",
          "shell.execute_reply.started": "2024-02-20T07:17:12.388703Z",
          "shell.execute_reply": "2024-02-20T07:17:12.405515Z"
        },
        "trusted": true,
        "id": "qNgT3GDdm_cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split the data into training and validation sets\n",
        "train_ds = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"training\"  # This is for training data\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:17:12.406894Z",
          "iopub.execute_input": "2024-02-20T07:17:12.407158Z",
          "iopub.status.idle": "2024-02-20T07:17:12.577224Z",
          "shell.execute_reply.started": "2024-02-20T07:17:12.40711Z",
          "shell.execute_reply": "2024-02-20T07:17:12.576437Z"
        },
        "trusted": true,
        "id": "9gEni04Wm_cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"validation\"  # This is for validation data\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:17:12.57823Z",
          "iopub.execute_input": "2024-02-20T07:17:12.578498Z",
          "iopub.status.idle": "2024-02-20T07:17:12.653623Z",
          "shell.execute_reply.started": "2024-02-20T07:17:12.578468Z",
          "shell.execute_reply": "2024-02-20T07:17:12.652652Z"
        },
        "trusted": true,
        "id": "3Py74XCRm_cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of classes\n",
        "classes = list(train_ds.class_indices.keys())\n",
        "print(classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:17:12.654813Z",
          "iopub.execute_input": "2024-02-20T07:17:12.655106Z",
          "iopub.status.idle": "2024-02-20T07:17:12.659833Z",
          "shell.execute_reply.started": "2024-02-20T07:17:12.655076Z",
          "shell.execute_reply": "2024-02-20T07:17:12.658898Z"
        },
        "trusted": true,
        "id": "qo_oqEATm_cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "# instantiate a distribution strategy\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "# instantiating the model in the strategy scope creates the model on the TPU\n",
        "with tpu_strategy.scope():\n",
        "    # importing the libraries\n",
        "    from keras.models import Model\n",
        "    from keras.layers import Flatten, Dense\n",
        "    from keras.applications import VGG16\n",
        "\n",
        "    IMAGE_SIZE = [128, 128]  # we will keep the image size as (64,64). You can increase the size for better results.\n",
        "\n",
        "    # loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
        "    vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
        "\n",
        "    # this will exclude the initial layers from the training phase as they have already been trained.\n",
        "    for layer in vgg.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(vgg.output)\n",
        "    x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
        "    x = Dense(31, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi-label classification problem.\n",
        "\n",
        "    model = Model(inputs = vgg.input, outputs = x)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'],steps_per_execution=32)\n",
        "    print(\"model created\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.18138Z",
          "iopub.status.idle": "2024-02-20T07:24:43.181676Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.181531Z",
          "shell.execute_reply": "2024-02-20T07:24:43.181544Z"
        },
        "trusted": true,
        "id": "PugFFx7mm_cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.182621Z",
          "iopub.status.idle": "2024-02-20T07:24:43.182898Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.182758Z",
          "shell.execute_reply": "2024-02-20T07:24:43.182772Z"
        },
        "trusted": true,
        "id": "dECBXXqym_cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n",
        "history = model.fit(train_ds, epochs=50, validation_data=val_ds, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.183915Z",
          "iopub.status.idle": "2024-02-20T07:24:43.184215Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.184058Z",
          "shell.execute_reply": "2024-02-20T07:24:43.184071Z"
        },
        "trusted": true,
        "id": "vSbQUaMim_cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['accuracy', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.184998Z",
          "iopub.status.idle": "2024-02-20T07:24:43.185297Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.185155Z",
          "shell.execute_reply": "2024-02-20T07:24:43.18517Z"
        },
        "trusted": true,
        "id": "soGawJk-m_cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_ds)\n",
        "print(f\"Training Accuracy: {train_accuracy*100: .2f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.186226Z",
          "iopub.status.idle": "2024-02-20T07:24:43.186553Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.186396Z",
          "shell.execute_reply": "2024-02-20T07:24:43.186413Z"
        },
        "trusted": true,
        "id": "llmHVA87m_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss, validation_accuracy = model.evaluate(val_ds)\n",
        "print(f\"Validation Accuracy: {train_accuracy*100: .2f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.187712Z",
          "iopub.status.idle": "2024-02-20T07:24:43.188034Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.187878Z",
          "shell.execute_reply": "2024-02-20T07:24:43.187894Z"
        },
        "trusted": true,
        "id": "g4btWBwXm_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_ds = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"validation\"  # Use a portion of the data for testing\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.191109Z",
          "iopub.status.idle": "2024-02-20T07:24:43.191411Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.191274Z",
          "shell.execute_reply": "2024-02-20T07:24:43.191288Z"
        },
        "trusted": true,
        "id": "MgzG_csgm_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.192212Z",
          "iopub.status.idle": "2024-02-20T07:24:43.192491Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.19235Z",
          "shell.execute_reply": "2024-02-20T07:24:43.192364Z"
        },
        "trusted": true,
        "id": "mMkbRi0Am_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('FRM.h5')\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Create a download link\n",
        "FileLink('FRM.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:24:43.193282Z",
          "iopub.status.idle": "2024-02-20T07:24:43.193566Z",
          "shell.execute_reply.started": "2024-02-20T07:24:43.193429Z",
          "shell.execute_reply": "2024-02-20T07:24:43.193443Z"
        },
        "trusted": true,
        "id": "pZCh1fh_m_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model-2 (Face Cropped & Splited Dataset)"
      ],
      "metadata": {
        "id": "GHLjMW5tm_cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# suppress display of warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:58:50.522017Z",
          "iopub.execute_input": "2024-02-16T16:58:50.522526Z",
          "iopub.status.idle": "2024-02-16T16:58:54.383646Z",
          "shell.execute_reply.started": "2024-02-16T16:58:50.522492Z",
          "shell.execute_reply": "2024-02-16T16:58:54.382726Z"
        },
        "trusted": true,
        "id": "yMCktOe-m_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the directory containing Haar cascade files\n",
        "cascade_dir = cv2.data.haarcascades\n",
        "\n",
        "# Path to the Haar cascade file for frontal face detection\n",
        "cascade_file = os.path.join(cascade_dir, 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Check if the cascade file exists\n",
        "if os.path.isfile(cascade_file):\n",
        "    print(\"Haar cascade file found:\", cascade_file)\n",
        "else:\n",
        "    print(\"Haar cascade file not found. Downloading...\")\n",
        "    cv2_base_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/\"\n",
        "    cascade_url = cv2_base_url + 'haarcascade_frontalface_default.xml'\n",
        "    os.system(f\"wget {cascade_url} -P {cascade_dir}\")\n",
        "    print(\"Haar cascade file downloaded successfully.\")\n",
        "\n",
        "# Now, you can use cascade_file as the filter_path in your code.\n",
        "filter_path = cascade_file"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:58:58.254554Z",
          "iopub.execute_input": "2024-02-16T16:58:58.255578Z",
          "iopub.status.idle": "2024-02-16T16:58:58.260961Z",
          "shell.execute_reply.started": "2024-02-16T16:58:58.25554Z",
          "shell.execute_reply": "2024-02-16T16:58:58.260234Z"
        },
        "trusted": true,
        "id": "yjH8MVVXm_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect faces and crop them from an image\n",
        "def detect_and_crop_faces(image):\n",
        "    face_cascade = cv2.CascadeClassifier(filter_path)\n",
        "    faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
        "    cropped_faces = []\n",
        "    for (x, y, w, h) in faces:\n",
        "        cropped_faces.append(image[y:y+h, x:x+w])\n",
        "    return cropped_faces\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:41:12.46796Z",
          "iopub.execute_input": "2024-02-16T16:41:12.46903Z",
          "iopub.status.idle": "2024-02-16T16:41:12.47452Z",
          "shell.execute_reply.started": "2024-02-16T16:41:12.468988Z",
          "shell.execute_reply": "2024-02-16T16:41:12.473236Z"
        },
        "trusted": true,
        "id": "6vqCMCwJm_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = \"/content/drive/My Drive/Computer Vision/Face Recognition/Original Images\"\n",
        "# Path to store the cropped images\n",
        "cropped_dataset_dir = \"/content/drive/My Drive/Computer Vision/Face Recognition/CroppedImages\"\n",
        "# Path to store the split train and test sets\n",
        "train_dir = os.path.join(cropped_dataset_dir, \"train\")\n",
        "test_dir = os.path.join(cropped_dataset_dir, \"test\")\n",
        "\n",
        "# Create directories for train and test sets\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Common size to which all face images will be resized\n",
        "common_size = (128, 128)\n",
        "\n",
        "# Iterate through each subdirectory (each person's folder)\n",
        "for subdir in os.listdir(dataset_dir):\n",
        "    subdir_path = os.path.join(dataset_dir, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        # Create corresponding subdirectories in train and test folders\n",
        "        train_subdir_path = os.path.join(train_dir, subdir)\n",
        "        test_subdir_path = os.path.join(test_dir, subdir)\n",
        "        os.makedirs(train_subdir_path, exist_ok=True)\n",
        "        os.makedirs(test_subdir_path, exist_ok=True)\n",
        "\n",
        "        # Get the list of image files in the subdirectory\n",
        "        image_files = [f for f in os.listdir(subdir_path) if f.endswith('.jpg')]\n",
        "\n",
        "        # Iterate through each image in the subdirectory\n",
        "        for image_name in image_files:\n",
        "            image_path = os.path.join(subdir_path, image_name)\n",
        "            # Read the image\n",
        "            img = cv2.imread(image_path)\n",
        "            # Detect and crop faces from the image (function detect_and_crop_faces to be defined)\n",
        "            faces = detect_and_crop_faces(img)\n",
        "            # Resize each face to a common size before appending to the list\n",
        "            for idx, face in enumerate(faces):\n",
        "                if face is not None:\n",
        "                    resized_face = cv2.resize(face, common_size)\n",
        "                    # Decide whether to put the image in train or test set\n",
        "                    if np.random.rand() < 0.9:  # 90% train, 10% test\n",
        "                        save_path = os.path.join(train_subdir_path, f\"{image_name}_{idx}.jpg\")\n",
        "                    else:\n",
        "                        save_path = os.path.join(test_subdir_path, f\"{image_name}_{idx}.jpg\")\n",
        "                    # Save the cropped face image\n",
        "                    cv2.imwrite(save_path, resized_face)\n",
        "print('dataset created')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:41:15.848359Z",
          "iopub.execute_input": "2024-02-16T16:41:15.849025Z",
          "iopub.status.idle": "2024-02-16T16:45:21.892457Z",
          "shell.execute_reply.started": "2024-02-16T16:41:15.848988Z",
          "shell.execute_reply": "2024-02-16T16:45:21.891241Z"
        },
        "trusted": true,
        "id": "dRSB0uVKm_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "img = mpimg.imread('/content/drive/My Drive/Computer Vision/Face Recognition/CroppedImages/train/Elizabeth Olsen/Elizabeth Olsen_64.jpg_0.jpg')\n",
        "imgplot = plt.imshow(img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:59:31.616115Z",
          "iopub.execute_input": "2024-02-16T16:59:31.616475Z",
          "iopub.status.idle": "2024-02-16T16:59:31.863829Z",
          "shell.execute_reply.started": "2024-02-16T16:59:31.616429Z",
          "shell.execute_reply": "2024-02-16T16:59:31.863098Z"
        },
        "trusted": true,
        "id": "CUnD7dNem_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anytree"
      ],
      "metadata": {
        "trusted": true,
        "id": "-w-gcsIRm_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from anytree import Node, RenderTree\n",
        "\n",
        "def create_directory_tree(root_path, parent=None):\n",
        "    \"\"\"\n",
        "    Recursively create a directory tree structure using AnyTree.\n",
        "    \"\"\"\n",
        "    node = Node(os.path.basename(root_path), parent=parent)\n",
        "    if os.path.isdir(root_path):\n",
        "        for item in sorted(os.listdir(root_path)):\n",
        "            item_path = os.path.join(root_path, item)\n",
        "            create_directory_tree(item_path, parent=node)\n",
        "\n",
        "def print_directory_tree(root_path):\n",
        "    \"\"\"\n",
        "    Print the directory tree structure using AnyTree.\n",
        "    \"\"\"\n",
        "    root = Node(os.path.basename(root_path))\n",
        "    create_directory_tree(root_path, root)\n",
        "    for pre, _, node in RenderTree(root):\n",
        "        print(\"%s%s\" % (pre, node.name))\n",
        "\n",
        "# Define the root directory\n",
        "root_dir = \"/CroppedImages\"\n",
        "\n",
        "# Print the directory tree\n",
        "print_directory_tree(root_dir)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "x1Q0rK3qm_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/My Drive/Computer Vision/Face Recognition/CroppedImages/train'\n",
        "test_dir = '/content/drive/My Drive/Computer Vision/Face Recognition/CroppedImages/test'\n",
        "\n",
        "# Using ImageDataGenerator for data augmentation\n",
        "generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1  # 10% of the data will be used for validation\n",
        ")\n",
        "\n",
        "# Load and split the data into training and validation sets\n",
        "train_ds = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"training\"  # This is for training data\n",
        ")\n",
        "\n",
        "val_ds = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"validation\"  # This is for validation data\n",
        ")\n",
        "\n",
        "# Get the list of classes\n",
        "classes = list(train_ds.class_indices.keys())\n",
        "print(\"Classes in training data:\", classes)\n",
        "\n",
        "# Load test data\n",
        "test_ds = generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"training\"  # This is for test data\n",
        ")\n",
        "\n",
        "# Get the list of classes in test data\n",
        "test_classes = list(test_ds.class_indices.keys())\n",
        "print(\"Classes in test data:\", test_classes)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T17:46:41.51781Z",
          "iopub.execute_input": "2024-02-16T17:46:41.518166Z",
          "iopub.status.idle": "2024-02-16T17:46:41.728451Z",
          "shell.execute_reply.started": "2024-02-16T17:46:41.51813Z",
          "shell.execute_reply": "2024-02-16T17:46:41.727498Z"
        },
        "trusted": true,
        "id": "-XTJ5Y0fm_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "# instantiating the model in the strategy scope creates the model on the TPU\n",
        "with tpu_strategy.scope():\n",
        "    # importing the librariesṇ\n",
        "    from keras.models import Model\n",
        "    from keras.layers import Flatten, Dense\n",
        "    from keras.applications import VGG16\n",
        "\n",
        "    IMAGE_SIZE = [128, 128]  # we will keep the image size as (64,64). You can increase the size for better results.\n",
        "\n",
        "    # loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
        "    vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
        "\n",
        "    # this will exclude the initial layers from the training phase as they have already been trained.\n",
        "    for layer in vgg.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(vgg.output)\n",
        "    x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
        "    x = Dense(31, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi-label classification problem.\n",
        "\n",
        "    model = Model(inputs = vgg.input, outputs = x)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(\"model created\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T17:00:00.785659Z",
          "iopub.execute_input": "2024-02-16T17:00:00.786051Z",
          "iopub.status.idle": "2024-02-16T17:00:09.441592Z",
          "shell.execute_reply.started": "2024-02-16T17:00:00.786018Z",
          "shell.execute_reply": "2024-02-16T17:00:09.440724Z"
        },
        "trusted": true,
        "id": "L1SUgDGQm_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T17:00:32.136396Z",
          "iopub.execute_input": "2024-02-16T17:00:32.136775Z",
          "iopub.status.idle": "2024-02-16T17:00:32.163254Z",
          "shell.execute_reply.started": "2024-02-16T17:00:32.136728Z",
          "shell.execute_reply": "2024-02-16T17:00:32.162548Z"
        },
        "trusted": true,
        "id": "PG2XOrKem_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n",
        "history = model.fit(train_ds, epochs=100, validation_data=val_ds, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T17:47:15.040234Z",
          "iopub.execute_input": "2024-02-16T17:47:15.040629Z",
          "iopub.status.idle": "2024-02-16T18:03:41.843604Z",
          "shell.execute_reply.started": "2024-02-16T17:47:15.040596Z",
          "shell.execute_reply": "2024-02-16T18:03:41.842614Z"
        },
        "trusted": true,
        "id": "RGg9qX8sm_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_ds)\n",
        "print(f\"Training Accuracy: {train_accuracy*100: .2f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:04:05.252997Z",
          "iopub.execute_input": "2024-02-16T18:04:05.253363Z",
          "iopub.status.idle": "2024-02-16T18:04:13.813421Z",
          "shell.execute_reply.started": "2024-02-16T18:04:05.253332Z",
          "shell.execute_reply": "2024-02-16T18:04:13.812529Z"
        },
        "trusted": true,
        "id": "CXLaMQJOm_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss, validation_accuracy = model.evaluate(val_ds)\n",
        "print(f\"Validation Accuracy: {train_accuracy*100: .2f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T17:08:53.381669Z",
          "iopub.execute_input": "2024-02-16T17:08:53.382068Z",
          "iopub.status.idle": "2024-02-16T17:08:54.929043Z",
          "shell.execute_reply.started": "2024-02-16T17:08:53.382037Z",
          "shell.execute_reply": "2024-02-16T17:08:54.928145Z"
        },
        "trusted": true,
        "id": "t8coVMP_m_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_ds = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset=\"validation\"  # Use a portion of the data for testing\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:04:49.029241Z",
          "iopub.execute_input": "2024-02-16T18:04:49.030105Z",
          "iopub.status.idle": "2024-02-16T18:04:49.09813Z",
          "shell.execute_reply.started": "2024-02-16T18:04:49.030062Z",
          "shell.execute_reply": "2024-02-16T18:04:49.097229Z"
        },
        "trusted": true,
        "id": "D55R_O5Ym_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:04:55.995354Z",
          "iopub.execute_input": "2024-02-16T18:04:55.996107Z",
          "iopub.status.idle": "2024-02-16T18:04:57.497628Z",
          "shell.execute_reply.started": "2024-02-16T18:04:55.996073Z",
          "shell.execute_reply": "2024-02-16T18:04:57.496707Z"
        },
        "trusted": true,
        "id": "CI1DH-bLm_cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['accuracy', 'val_accuracy', 'loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:05:00.847156Z",
          "iopub.execute_input": "2024-02-16T18:05:00.847666Z",
          "iopub.status.idle": "2024-02-16T18:05:01.034369Z",
          "shell.execute_reply.started": "2024-02-16T18:05:00.847635Z",
          "shell.execute_reply": "2024-02-16T18:05:01.0336Z"
        },
        "trusted": true,
        "id": "TGRhVru2m_cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['accuracy', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:05:13.704657Z",
          "iopub.execute_input": "2024-02-16T18:05:13.705003Z",
          "iopub.status.idle": "2024-02-16T18:05:14.083971Z",
          "shell.execute_reply.started": "2024-02-16T18:05:13.704974Z",
          "shell.execute_reply": "2024-02-16T18:05:14.083131Z"
        },
        "trusted": true,
        "id": "PgsRrdjcm_cO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}